#!/usr/bin/env python3
"""
Test LLM Integration
====================

This script tests the LLM integration for the coaching system.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def test_llm_imports():
    """Test if LLM modules can be imported"""
    try:
        from src.llm import LLMClient, LLMResponse
        print("‚úÖ LLM imports successful")
        return True
    except ImportError as e:
        print(f"‚ùå LLM import failed: {e}")
        return False

def test_coaching_imports():
    """Test if coaching modules can be imported"""
    try:
        from src.coaching import CoachingAgent, CoachingContext, CoachingFeedback
        print("‚úÖ Coaching imports successful")
        return True
    except ImportError as e:
        print(f"‚ùå Coaching import failed: {e}")
        return False

def test_config_loading():
    """Test if LLM configuration can be loaded"""
    try:
        from config import LLM_CONFIG
        print(f"‚úÖ LLM config loaded: {LLM_CONFIG['provider']}")
        return True
    except ImportError as e:
        print(f"‚ùå Config import failed: {e}")
        return False

def test_llm_client_creation():
    """Test if LLM client can be created"""
    try:
        from config import LLM_CONFIG
        from src.llm import LLMClient
        
        client = LLMClient(LLM_CONFIG)
        print(f"‚úÖ LLM client created: {client.provider}")
        return client
    except Exception as e:
        print(f"‚ùå LLM client creation failed: {e}")
        return None

def test_ollama_connection():
    """Test Ollama connection"""
    try:
        from config import LLM_CONFIG
        from src.llm import LLMClient
        
        client = LLMClient(LLM_CONFIG)
        if client.provider == 'ollama':
            connection_ok = client.test_connection()
            if connection_ok:
                print("‚úÖ Ollama connection successful")
            else:
                print("‚ö†Ô∏è Ollama connection failed - make sure Ollama is running")
            return connection_ok
        else:
            print(f"‚ÑπÔ∏è Not testing Ollama (provider: {client.provider})")
            return True
    except Exception as e:
        print(f"‚ùå Ollama connection test failed: {e}")
        return False

def test_coaching_agent():
    """Test coaching agent creation"""
    try:
        from src.coaching import CoachingAgent
        
        agent = CoachingAgent()
        print("‚úÖ Coaching agent created successfully")
        return agent
    except Exception as e:
        print(f"‚ùå Coaching agent creation failed: {e}")
        return None

def main():
    """Run all tests"""
    print("üß† Testing LLM Integration")
    print("=" * 40)
    
    # Test imports
    llm_ok = test_llm_imports()
    coaching_ok = test_coaching_imports()
    config_ok = test_config_loading()
    
    if not all([llm_ok, coaching_ok, config_ok]):
        print("\n‚ùå Basic imports failed - cannot proceed")
        return
    
    # Test LLM client
    client = test_llm_client_creation()
    if not client:
        print("\n‚ùå LLM client creation failed")
        return
    
    # Test connection
    connection_ok = test_ollama_connection()
    
    # Test coaching agent
    agent = test_coaching_agent()
    if not agent:
        print("\n‚ùå Coaching agent creation failed")
        return
    
    print("\n" + "=" * 40)
    if connection_ok:
        print("üéâ All tests passed! LLM integration is ready.")
        print("\nüí° To use AI coaching:")
        print("   1. Make sure Ollama is running")
        print("   2. Run: ollama run llama2")
        print("   3. Use the coaching feature in the Streamlit app")
    else:
        print("‚ö†Ô∏è Tests completed with warnings.")
        print("\nüí° The system will fall back to rule-based coaching")
        print("   until Ollama is available.")

if __name__ == "__main__":
    main()
